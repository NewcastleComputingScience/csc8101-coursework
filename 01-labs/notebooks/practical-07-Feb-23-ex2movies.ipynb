{"cells":[{"cell_type":"markdown","source":["## CSC8101 - Practical 07 Feb 2023\n\n#### Exercise 2 - Movies Dataset - Take home\n\nTwo input [datasets](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset):\n\n- `ratings` dataset: Movie ratings from 270,000 users for all 45,000 movies. Ratings are on a scale of 1-5 and have been obtained from the official GroupLens website.\n- `movies` dataset: The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset.\n\nEach of these datasets is read into a DataFrame below.\n\n##### Task 1\n\n1. How many partitions has each dataset?\n2. How big is each dataset? (Report number of columns)\n3. Repartition the `ratings` dataset by key `movieID` across `100` partitions.\n4. Verify that the `ratings` dataset now has `100` partitions.\n\nDocs:\n- [Repartition](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.repartition.html)\n\n##### Task 2\n\nWrite a data pipeline function that takes as input the two datasets above and outputs the `N` most popular films (by rating), for a given `genre`, for a given `decade` (specified by its start year, e.g. `1980` for 80s and `2000` for 2000s).\n\n> Example function run: `pipeline(N = 10, genre = \"comedy\", decade = 2010)`\n\nRun your function for the following parameter inputs and report your findings. Set `N = 10` throughout:\n\n- `genre = \"Thriller\"`, `decade = 1980`\n- `genre = \"Drama\"`, `decade = 2000`\n- `genre = \"Comedy\"`, `decade = 2010`\n\nHelpful docs:\n\n- [DataFrame quickstart](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html?highlight=select)\n- [withColumn](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.withColumn.html?highlight=withcolumn#pyspark.sql.DataFrame.withColumn)\n- [select](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html#pyspark.sql.DataFrame.select)\n- [orderBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.orderBy.html?highlight=orderby#pyspark.sql.DataFrame.orderBy)\n- [join](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html?highlight=join#pyspark.sql.DataFrame.join)\n- [filter](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html?highlight=filter#pyspark.sql.DataFrame.filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6169af9e-c020-42ef-9497-2cbb3ae0d59a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.functions as FN"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c738fe52-bcf0-4534-8ff2-ac872796c1a2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Task 1\n\n# File location and type\nratings_file_location = \"/FileStore/tables/movies/ratings.csv\"\nmovies_file_location = \"/FileStore/tables/movies/movies_metadata.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\nratings = spark.read.format(file_type) \\\n          .option(\"inferSchema\", infer_schema) \\\n          .option(\"header\", first_row_is_header) \\\n          .option(\"sep\", delimiter) \\\n          .load(ratings_file_location)\n\nmovies = spark.read.format(file_type) \\\n          .option(\"inferSchema\", infer_schema) \\\n          .option(\"header\", first_row_is_header) \\\n          .option(\"sep\", delimiter) \\\n          .load(movies_file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dec4e3ad-352d-485f-b08c-0bc1fd0eafa8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(ratings.take(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8aec71a3-c178-45c5-b307-a162c814c130","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(movies.printSchema())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6eac2330-95fc-4ed5-9fc2-8dfadc7909af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["movies[['genres']].take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"91860a48-9225-40b0-b03a-ef7cff268666","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Task 1 - Partition datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a19e2589-a1d5-416d-a581-93996f8fc297","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# write your solution here"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f8d3821b-a955-408e-abc6-e60c31817d90","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Task 2 - Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da0fee41-89f0-45f1-9c00-09b3e150bfde","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# write your solution here"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5525c5e-5414-4004-b3f7-65d413ce3d2e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"practical-07-Feb-23-ex2movies","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2924639093044607}},"nbformat":4,"nbformat_minor":0}
