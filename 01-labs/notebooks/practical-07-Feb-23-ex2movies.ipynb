{"cells":[{"cell_type":"markdown","source":["## CSC8101 - Practical 07 Feb 2023\n\n#### Exercise 2 - Movies Dataset - Take home\n\nTwo input [datasets](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset):\n\n- `ratings` dataset: Movie ratings from 270,000 users for all 45,000 movies. Ratings are on a scale of 1-5 and have been obtained from the official GroupLens website.\n- `movies` dataset: The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset.\n\nEach of these datasets is read into a DataFrame below.\n\n##### Task 1\n\n1. How many partitions has each dataset?\n2. How big is each dataset? (Report number of rows)\n3. Repartition the `ratings` dataset by key `movieID` across `100` partitions.\n4. Verify that the `ratings` dataset now has `100` partitions.\n\nDocs:\n- [Repartition](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.repartition.html)\n\n##### Task 2\n\nWrite a data pipeline function that takes as input the two datasets above and outputs the `N` most popular films (by rating), for a given `genre`, for a given `decade` (specified by its start year, e.g. `1980` for 80s and `2000` for 2000s).\n\n> Example function run: `pipeline(N = 10, genre = \"comedy\", decade = 2010)`\n\nRun your function for the following parameter inputs and report your findings. Set `N = 10` throughout:\n\n- `genre = \"Thriller\"`, `decade = 1980`\n- `genre = \"Drama\"`, `decade = 2000`\n- `genre = \"Comedy\"`, `decade = 2010`\n\nHelpful docs:\n\n- [DataFrame quickstart](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html?highlight=select)\n- [withColumn](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.withColumn.html?highlight=withcolumn#pyspark.sql.DataFrame.withColumn)\n- [select](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html#pyspark.sql.DataFrame.select)\n- [orderBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.orderBy.html?highlight=orderby#pyspark.sql.DataFrame.orderBy)\n- [join](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html?highlight=join#pyspark.sql.DataFrame.join)\n- [filter](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html?highlight=filter#pyspark.sql.DataFrame.filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6169af9e-c020-42ef-9497-2cbb3ae0d59a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.functions as FN\nimport pyspark.sql.types as TP\n\n# Task 1\n\n# File location and type\nratings_file_location = \"/FileStore/tables/movies/ratings.csv\"\nmovies_file_location = \"/FileStore/tables/movies/movies_metadata.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n\n\n# The applied options are for CSV files. For other file types, these will be ignored.\nratings = spark.read.format(file_type) \\\n          .option(\"inferSchema\", infer_schema) \\\n          .option(\"header\", first_row_is_header) \\\n          .option(\"sep\", delimiter) \\\n          .load(ratings_file_location)\n\nmovies_metadata = spark.read.format(file_type) \\\n                  .option(\"inferSchema\", infer_schema) \\\n                  .option(\"header\", first_row_is_header) \\\n                  .option(\"sep\", delimiter) \\\n                  .load(movies_file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dec4e3ad-352d-485f-b08c-0bc1fd0eafa8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(ratings.take(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e252dbd0-639d-4d59-a575-0b3ab613b280","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(movies_metadata.printSchema())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b17f9f0d-74be-4713-9994-b0b7fb2c38d0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["movies_metadata[['genres']].take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21eeb86c-0a5b-4c78-9077-eb30df743d21","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Initial pre-processing\n\n## Select relevant columns\nmovies = movies_metadata[['id','original_title','genres','release_date']]\n\n## sample data\ndisplay(movies.take(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"62c44126-21b5-4e2a-8428-88002837e296","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Notice that genres is a string but that's not very useful - so we need to make it a structure that can be \n# In this case that is an array of dicts with key set ('id', 'name')\n\n\n# schema for 'genres' column in movies metadata dataset\ngenres_schema = TP.ArrayType(\n    TP.StructType([\n        TP.StructField(\"id\", TP.IntegerType()),\n        TP.StructField(\"name\", TP.StringType())\n    ])\n)\n\n# Now we overwrite columns 'genres' to parse the string into a data structure that we can manipulate\nmovies = movies.withColumn(\"genres\", FN.from_json(movies.genres, genres_schema))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af1345db-30c4-4534-875a-d50dbe5851be","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(movies.printSchema())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f81c019c-563b-41ad-98bd-fba1e682c5f3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Task 1 - Partition `ratings` dataset\n\n1. How many partitions has each dataset?\n2. How big is each dataset? (Report number of rows)\n3. Repartition the `ratings` dataset by key `movieID` across `100` partitions.\n4. Verify that the `ratings` dataset now has `100` partitions."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a19e2589-a1d5-416d-a581-93996f8fc297","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# write your solution here"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f8d3821b-a955-408e-abc6-e60c31817d90","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 1\nprint(\"# 1\")\nprint(f\"Number of partitions (ratings): {ratings.rdd.getNumPartitions()}\")\nprint(f\"Number of partitions (movies): {movies.rdd.getNumPartitions()}\")\n\n# 2\nprint(\"# 2\")\nprint(\"Number of rows (ratings): {t:,}\".format(t = ratings.count()))\nprint(\"Number of rows (movies): {t:,}\".format(t = movies.count()))\n\n# 3\nprint(\"# 3\")\nratings_100part = ratings.repartition(100, \"movieID\")\nprint(f\"Number of partitions (ratings): {ratings_100part.rdd.getNumPartitions()}\")\nprint(f\"Number of partitions (movies): {movies.rdd.getNumPartitions()}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c0d93f4-da03-4b99-8fe0-c042df6d9764","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Task 2 - Pipeline\n\nWrite a data pipeline function that takes as input the two datasets above and outputs the `N` most popular films (by rating), for a given `genre`, for a given `decade` (specified by its start year, e.g. `1980` for 80s and `2000` for 2000s)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da0fee41-89f0-45f1-9c00-09b3e150bfde","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def movies_pipeline(movies_df, ratings_df, N = 10, genre = \"Comedy\", decade = 1980):\n    # write your solution here\n    # develop your solution in separate cells before implementing this function    \n    pass"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5525c5e-5414-4004-b3f7-65d413ce3d2e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2a. Begin by further pre-processing the movies dataframe\n\nSave the output of this sequence of operations into a new variable.\n\n- Extract the name of each genre in column `genres`\n- Convert date string to datetime structure in column `release_date`\n- Remove movies with null date values\n- Create new column `year` from `release_date`\n- Drop the `release_date` column\n\nDocs:\n\n- [Operations on columns - Pyspark functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html) (used within `withColumn` or `select`)\n- [Operations on DataFrames](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html)\n- [withColumn](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.withColumn.html?highlight=withcolumn#pyspark.sql.DataFrame.withColumn)\n- [filter](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html?highlight=filter#pyspark.sql.DataFrame.filter)\n- [drop](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.drop.html#pyspark.sql.DataFrame.drop)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69c83bec-9cd6-4b31-bc0d-e649ce284cc9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["processed = (\n    movies.withColumn('genres', FN.transform(movies.genres, lambda x: x['name'])) # extract genre name\n      .withColumn('release_date', FN.to_timestamp(movies.release_date, \"yyyy-MM-dd\")) # date string to datetime structure\n      .filter(FN.col('release_date').isNotNull()) # remove movies with null dates\n      .withColumn('year', FN.year(FN.col('release_date'))) # extract year from date\n      .drop('release_date')\n)\n\nprocessed.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ec07a7a0-b00d-4807-96cb-9ccb67b5c8da","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2b. Filter the processed movies dataset based on parameters `genre` and `decade`\n\nSave the output of this sequence of operations into a new variable.\n\nDocs:\n\n- [Operations on columns - Pyspark functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html) (used within `withColumn` or `select`)\n- [filter](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.filter.html?highlight=filter#pyspark.sql.DataFrame.filter)\n\nHints:\n\n- Each film can have multiple genres. What is the pyspark function that allows you to find whether an array contains an element?\n- How can we calculate that a given year is part of a decade? There's a simple mathematical formula.."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1af93dbb-c7a5-45cd-a3ee-78701319e2d6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["genre = \"Thriller\"\ndecade = 1980\n\nsubset = processed.filter(FN.array_contains(FN.col('genres'), genre))\\\n                  .filter(\n                     (FN.col('year') - decade >= 0) & \n                     (FN.col('year') - decade < 10))\n\nsubset.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"97482e01-d640-4eb6-9603-2eceab031dbe","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2c. Calculate the average rating of each film in the ratings dataset\n\nSave the output of this opepration into a new variable.\n\nDocs:\n\n- [groupBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.groupBy.html#pyspark.sql.DataFrame.groupBy)\n- [agg](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.agg.html#pyspark.sql.DataFrame.agg)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b523417b-ca02-4f03-9c08-590d54e768ce","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["avg_ratings = ratings.groupBy('movieID').agg(FN.avg(ratings.rating).alias('avg_rating'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a16061af-e2cf-4f21-bfaf-aa1b6f442ed9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2d. Join the result of 2b with 2c, order by avg rating (desceding order) and select top N\n\nDocs:\n\n- [join](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html?highlight=join#pyspark.sql.DataFrame.join)\n- [orderBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.orderBy.html?highlight=orderby#pyspark.sql.DataFrame.orderBy)\n- [select](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html#pyspark.sql.DataFrame.select)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c9857070-de5c-47ab-9d83-9752ef9bb67c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["N = 10\n\nresult = subset.join(avg_ratings, subset.id == avg_ratings.movieID, how = \"inner\")\\\n               .orderBy(FN.col('avg_rating').desc())\\\n               .select(['original_title', 'year', 'avg_rating'])\\\n               .take(N)\n\ndisplay(result)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d1d088bd-b4cf-4f5f-b375-aa74502c8c65","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 2e. Put everything together in a function"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09e59fd2-a7f1-44db-a0c4-28875ee258ce","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def movies_pipeline(movies_df, ratings_df, N = 10, genre = \"Comedy\", decade = 1980):\n    # write your solution here\n    # develop your solution in separate cells before implementing this function\n    \n    # further pre-processing of movies dataframe\n    movies_processed = (\n      movies_df.withColumn('genres', FN.transform(movies.genres, lambda x: x['name'])) # extract genre name\n               .withColumn('release_date', FN.to_timestamp(movies.release_date, \"yyyy-MM-dd\")) # date string to datetime structure\n               .filter(FN.col('release_date').isNotNull()) # remove movies with null dates\n               .withColumn('year', FN.year(FN.col('release_date'))) # extract year from date\n               .drop('release_date')\n    )\n    \n    # filter movies based on parameters genre and decade\n    movie_subset = movies_processed.filter(FN.array_contains(FN.col('genres'), genre))\\\n                                   .filter(\n                                        (FN.col('year') - decade >= 0) & \n                                        (FN.col('year') - decade < 10))\n    \n    # ratings dataset: calculate avg ratings for each movie\n    total_ratings = ratings_df.groupBy('movieID').agg(FN.avg(ratings_df.rating).alias('avg_rating'))\n    \n    # join with ratings, calculate total ratings and select top N\n    out = movie_subset.join(total_ratings, movie_subset.id == total_ratings.movieID, how = \"inner\")\\\n                      .orderBy(FN.col('avg_rating').desc())\\\n                      .select(['original_title', 'year', 'avg_rating'])\\\n                      .take(N)\n    \n    return out"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"31cfcdeb-c4de-4106-9c21-21345ab2febe","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(\n    movies_pipeline(movies, ratings, genre = \"Thriller\", decade = 1980, N = 10)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"05e7914f-e9a9-46e8-b3de-73415df75874","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Scarface",1983,4.0893090376222485],["Lethal Weapon 2",1989,4.06918449197861],["The Falcon and the Snowman",1985,4.013636363636364],["48 Hrs.",1982,3.884030583809391],["Apartment Zero",1988,3.857142857142857],["Garde à vue",1981,3.8126293995859215],["Star Trek II: The Wrath of Khan",1982,3.795300982800983],["Die Hard",1988,3.763978263978264],["Black Rain",1989,3.694737696930323],["Messenger of Death",1988,3.681395348837209]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"original_title","type":"\"string\"","metadata":"{}"},{"name":"year","type":"\"long\"","metadata":"{}"},{"name":"avg_rating","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>original_title</th><th>year</th><th>avg_rating</th></tr></thead><tbody><tr><td>Scarface</td><td>1983</td><td>4.0893090376222485</td></tr><tr><td>Lethal Weapon 2</td><td>1989</td><td>4.06918449197861</td></tr><tr><td>The Falcon and the Snowman</td><td>1985</td><td>4.013636363636364</td></tr><tr><td>48 Hrs.</td><td>1982</td><td>3.884030583809391</td></tr><tr><td>Apartment Zero</td><td>1988</td><td>3.857142857142857</td></tr><tr><td>Garde à vue</td><td>1981</td><td>3.8126293995859215</td></tr><tr><td>Star Trek II: The Wrath of Khan</td><td>1982</td><td>3.795300982800983</td></tr><tr><td>Die Hard</td><td>1988</td><td>3.763978263978264</td></tr><tr><td>Black Rain</td><td>1989</td><td>3.694737696930323</td></tr><tr><td>Messenger of Death</td><td>1988</td><td>3.681395348837209</td></tr></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"practical-07-Feb-23-ex2movies","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2924639093044607}},"nbformat":4,"nbformat_minor":0}
